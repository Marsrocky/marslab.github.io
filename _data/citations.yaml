# DO NOT EDIT, GENERATED AUTOMATICALLY

- id: doi:10.1016/j.patter.2023.100703
  title: 'SenseFi: A library and benchmark on deep-learning-empowered WiFi human sensing'
  authors:
  - Jianfei Yang
  - Xinyan Chen
  - Han Zou
  - Chris Xiaoxuan Lu
  - Dazhuo Wang
  - Sumei Sun
  - Lihua Xie
  publisher: Patterns, Cell Press
  date: '2023-03-10'
  link: https://doi.org/gsmbtr
  type: paper
  description: The world-first open-source benchmark on deep learning-empowered WiFi
    sensing.
  image: https://ars.els-cdn.com/content/image/1-s2.0-S2666389923000405-gr3.jpg
  buttons:
  - type: paper
    link: https://www.cell.com/patterns/fulltext/S2666-3899(23)00040-5
  - type: github
    text: Github
    link: xyanchen/WiFi-CSI-Sensing-Benchmark
  tags:
  - wifi sensing
  - benchmark
  plugin: sources.py
  file: sources.yaml
- id: arxiv:2305.10345
  title: 'MM-Fi: Multi-Modal Non-Intrusive 4D Human Dataset for Versatile Wireless
    Sensing'
  authors:
  - Jianfei Yang
  - He Huang
  - Yunjiao Zhou
  - Xinyan Chen
  - Yuecong Xu
  - Shenghai Yuan
  - Han Zou
  - Chris Xiaoxuan Lu
  - Lihua Xie
  publisher: NeurIPS 2023 Datasets and Benchmarks Track
  date: '2023-05-11'
  link: https://arxiv.org/abs/2305.10345
  type: paper
  description: The world-first multi-modal non-intrusive 4D human dataset (RGB, Depth,
    LiDAR, mmWave, WiFi).
  image: https://ntu-aiot-lab.github.io/static/images/setup.png
  buttons:
  - type: paper
    link: https://arxiv.org/pdf/2305.10345
  - type: github
    text: Github
    link: ybhbingo/MMFi_dataset
  - type: website
    text: Website
    link: https://ntu-aiot-lab.github.io/mm-fi
  tags:
  - multimodal dataset
  - 4D human sensing
  - human pose estimation
  - non-intrusive sensing
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1007/s11263-023-01932-5
  title: 'Going Deeper into Recognizing Actions in Dark Environments: A Comprehensive
    Benchmark Study'
  authors:
  - Yuecong Xu
  - Haozhi Cao
  - Jianxiong Yin
  - Zhenghua Chen
  - Xiaoli Li
  - Zhengguo Li
  - Qianwen Xu
  - Jianfei Yang
  publisher: International Journal of Computer Vision
  date: '2023-11-08'
  link: https://doi.org/g8pwz3
  type: paper
  image: images/papers/yuecong-ijcv-23.png
  buttons:
  - type: paper
    text: Arxiv
    link: https://arxiv.org/pdf/2202.09545
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/ICCV51070.2023.01724
  title: Multi-Modal Continual Test-Time Adaptation for 3D Semantic Segmentation
  authors:
  - Haozhi Cao
  - Yuecong Xu
  - Jianfei Yang
  - Pengyu Yin
  - Shenghai Yuan
  - Lihua Xie
  publisher: 2023 IEEE/CVF International Conference on Computer Vision (ICCV)
  date: '2023-10-01'
  link: https://doi.org/g8pxwc
  type: paper
  image: images/papers/haozhi-mmctta-iccv23.png
  buttons:
  - type: paper
    link: https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf
  - type: website
    text: Website
    link: https://sites.google.com/view/mmcotta
  tags:
  - multimodal learning
  - test-time adaptation
  plugin: sources.py
  file: sources.yaml
- id: doi:10.48550/arXiv.2305.18712
  title: Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?
  authors:
  - Jianfei Yang
  - Hanjie Qian
  - Yuecong Xu
  - Kai Wang
  - Lihua Xie
  publisher: ICLR 2024
  date: '2024-01-01'
  link: https://doi.org/g8pxwd
  image: images/papers/transfer-score.png
  buttons:
  - type: github
    text: Github
    link: sleepyseal/TransferScore
  - type: website
    text: Website
    link: https://sleepyseal.github.io/TransferScoreWeb/
  - type: paper
    link: https://openreview.net/pdf?id=fszrlQ2DuP
  tags:
  - domain adaptation
  - unsupervised evaluation
  - model selection
  plugin: sources.py
  file: sources.yaml
- id: arXiv:2205.14467
  title: 'Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box
    Predictors'
  authors:
  - Jianfei Yang
  - Xiangyu Peng
  - Kai Wang
  - Zheng Zhu
  - Jiashi Feng
  - Lihua Xie
  - Yang You
  publisher: ICLR 2023
  date: '2023-01-01'
  link: https://arxiv.org/abs/2205.14467
  image: images/papers/jianfei-beta-iclr23.png
  buttons:
  - type: paper
    link: https://arxiv.org/pdf/2205.14467
  - type: github
    text: Github
    link: xyupeng/BETA
  tags:
  - domain adaptation
  - trustworthy AI
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/JIOT.2023.3262940
  title: 'MetaFi++: WiFi-Enabled Transformer-Based Human Pose Estimation for Metaverse
    Avatar Simulation'
  authors:
  - Yunjiao Zhou
  - He Huang
  - Shenghai Yuan
  - Han Zou
  - Lihua Xie
  - Jianfei Yang
  publisher: IEEE Internet of Things Journal (IoT-J)
  date: '2023-08-15'
  link: https://doi.org/g8qc4m
  image: images/gif/metafi.gif
  buttons:
  - type: paper
    link: https://ieeexplore.ieee.org/document/10086600
  - type: github
    text: Github
    link: pridy999/metafi_pose_estimation
  tags:
  - human pose estimation
  - wifi sensing
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1109/ICRA57147.2024.10610316
  title: 'MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation'
  authors:
  - Haozhi Cao
  - Yuecong Xu
  - Jianfei Yang
  - Pengyu Yin
  - Shenghai Yuan
  - Lihua Xie
  publisher: 2024 IEEE International Conference on Robotics and Automation (ICRA)
  date: '2024-05-13'
  link: https://doi.org/g8qdjg
  image: images/papers/haozhi-mopa-icra24.gif
  buttons:
  - type: paper
    text: Arxiv
    link: https://arxiv.org/pdf/2309.11839
  - type: github
    text: Github
    link: AronCao49/MoPA
  tags:
  - multimodal learning
  - domain adaptation
  - 3D semantic segmentation
  plugin: sources.py
  file: sources.yaml
- id: arxiv:2403.06461
  title: Reliable Spatial-Temporal Voxels For Multi-Modal Test-Time Adaptation
  authors:
  - Haozhi Cao
  - Yuecong Xu
  - Jianfei Yang
  - Pengyu Yin
  - Xingyu Ji
  - Shenghai Yuan
  - Lihua Xie
  publisher: European Conference on Computer Vision (ECCV), 2024
  date: '2024-07-26'
  link: https://arxiv.org/abs/2403.06461
  type: paper
  image: images/papers/haozhi-latte-eccv24.png
  buttons:
  - type: paper
    link: https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04076.pdf
  - type: github
    text: Github
    link: AronCao49/Latte
  - type: website
    text: Website
    link: https://sites.google.com/view/eccv24-latte
  tags:
  - Multimodal learning
  - Test-time adaptation
  plugin: sources.py
  file: sources.yaml
- id: doi:10.1145/3679010
  title: 'Video Unsupervised Domain Adaptation with Deep Learning: A Comprehensive
    Survey'
  authors:
  - Yuecong Xu
  - Haozhi Cao
  - Lihua Xie
  - Xiao-li Li
  - Zhenghua Chen
  - Jianfei Yang
  publisher: ACM Computing Surveys
  date: '2024-10-01'
  link: https://doi.org/g8pwzk
  image: images/papers/yuecong-vuda-survey.png
  buttons:
  - type: paper
    link: https://dl.acm.org/doi/10.1145/3679010
  - type: github
    text: Github
    link: xuyu0010/awesome-video-domain-adaptation
  tags:
  - video domain adaptation
  - survey
  plugin: sources.py
  file: sources.yaml
- id: arXiv:2410.10167
  title: 'X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing'
  authors:
  - Xinyan Chen
  - Jianfei Yang
  publisher: arXiv
  date: '2024-10-21'
  link: https://arxiv.org/abs/2410.10167
  image: images/papers/xinyan-xfi-iclr25.png
  buttons:
  - type: paper
    link: https://doi.org/10.48550/arXiv.2410.10167
  - type: github
    text: Github
    link: xyanchen/X-Fi
  - type: website
    text: Website
    link: https://xyanchen.github.io/X-Fi
  tags:
  - Multimodal learning
  - Foundation model
  plugin: sources.py
  file: sources.yaml
