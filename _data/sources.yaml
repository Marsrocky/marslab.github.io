- id: doi:10.1016/j.patter.2023.100703
  type: paper
  publisher: Patterns, Cell Press
  description: The world-first open-source benchmark on deep learning-empowered WiFi sensing.
  date: 2023-03-10
  image: https://ars.els-cdn.com/content/image/1-s2.0-S2666389923000405-gr3.jpg
  buttons:
    - type: paper
      link: https://www.cell.com/patterns/fulltext/S2666-3899(23)00040-5
    - type: github
      text: Github
      link: xyanchen/WiFi-CSI-Sensing-Benchmark
  tags:
    - wifi sensing
    - benchmark
- id: arxiv:2305.10345
  type: paper
  publisher: NeurIPS 2023 Datasets and Benchmarks Track
  description: The world-first multi-modal non-intrusive 4D human dataset (RGB, Depth, LiDAR, mmWave, WiFi).
  date: 2023-05-11
  image: https://ntu-aiot-lab.github.io/static/images/setup.png
  buttons:
    - type: paper
      link: https://arxiv.org/pdf/2305.10345
    - type: github
      text: Github
      link: ybhbingo/MMFi_dataset
    - type: website
      text: Website
      link: https://ntu-aiot-lab.github.io/mm-fi
  tags:
    - multimodal dataset
    - 4D human sensing
    - human pose estimation
    - non-intrusive sensing
- id: doi:10.1007/s11263-023-01932-5
  type: paper
  image: images/papers/yuecong-ijcv-23.png
  buttons:
    - type: paper
      text: Arxiv
      link: https://arxiv.org/pdf/2202.09545
- id: doi:10.1109/ICCV51070.2023.01724
  type: paper
  image: images/papers/haozhi-mmctta-iccv23.png
  buttons:
    - type: paper
      link: https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf
    - type: website
      text: Website
      link: https://sites.google.com/view/mmcotta
  tags:
    - multimodal learning
    - test-time adaptation
- id: doi:10.48550/arXiv.2305.18712
  publisher: ICLR 2024
  date: 2024-01-01
  image: images/papers/transfer-score.png
  buttons:
    - type: github
      text: Github
      link: sleepyseal/TransferScore
    - type: website
      text: Website
      link: https://sleepyseal.github.io/TransferScoreWeb/
    - type: paper
      link: https://openreview.net/pdf?id=fszrlQ2DuP
  tags:
    - domain adaptation
    - unsupervised evaluation
    - model selection
- id: arXiv:2205.14467
  publisher: ICLR 2023
  image: images/papers/jianfei-beta-iclr23.png
  date: 2023-01-01
  buttons:
    - type: paper
      link: https://arxiv.org/pdf/2205.14467
    - type: github
      text: Github
      link: xyupeng/BETA
  tags:
    - domain adaptation
    - trustworthy AI
- id: doi:10.1109/JIOT.2023.3262940
  publisher: IEEE Internet of Things Journal (IoT-J)
  image: images/gif/metafi.gif
  buttons:
    - type: paper
      link: https://ieeexplore.ieee.org/document/10086600
    - type: github
      text: Github
      link: pridy999/metafi_pose_estimation
  tags:
    - human pose estimation
    - wifi sensing
- id: doi:10.1109/ICRA57147.2024.10610316
  image: images/papers/haozhi-mopa-icra24.gif
  buttons:
    - type: paper
      text: Arxiv
      link: https://arxiv.org/pdf/2309.11839
    - type: github
      text: Github
      link: AronCao49/MoPA
  tags:
    - multimodal learning
    - domain adaptation
    - 3D semantic segmentation
- id: arxiv:2403.06461
  type: paper
  publisher: European Conference on Computer Vision (ECCV), 2024
  image: images/papers/haozhi-latte-eccv24.png
  buttons:
    - type: paper
      link: https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04076.pdf
    - type: github
      text: Github
      link: AronCao49/Latte
    - type: website
      text: Website
      link: https://sites.google.com/view/eccv24-latte
  tags:
    - Multimodal learning
    - Test-time adaptation
- id: doi:10.1145/3679010
  image: images/papers/yuecong-vuda-survey.png
  buttons:
    - type: paper
      link: https://dl.acm.org/doi/10.1145/3679010
    - type: github
      text: Github
      link: xuyu0010/awesome-video-domain-adaptation
  tags:
    - video domain adaptation
    - survey
- id: arXiv:2410.10167
  image: images/papers/xinyan-xfi-iclr25.png
  buttons:
    - type: paper
      link: https://doi.org/10.48550/arXiv.2410.10167
    - type: github
      text: Github
      link: xyanchen/X-Fi
    - type: website
      text: Website
      link: https://xyanchen.github.io/X-Fi
  tags:
    - Multimodal learning
    - Foundation model
